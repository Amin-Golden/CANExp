{"ast":null,"code":"'use strict';\n/* @flow */\n\n/**\n * [Simple linear regression](http://en.wikipedia.org/wiki/Simple_linear_regression)\n * is a simple way to find a fitted line\n * between a set of coordinates. This algorithm finds the slope and y-intercept of a regression line\n * using the least sum of squares.\n *\n * @param {Array<Array<number>>} data an array of two-element of arrays,\n * like `[[0, 1], [2, 3]]`\n * @returns {Object} object containing slope and intersect of regression line\n * @example\n * linearRegression([[0, 0], [1, 1]]); // => { m: 1, b: 0 }\n */\n\nfunction linearRegression(data\n/*: Array<Array<number>> */\n)\n/*: { m: number, b: number } */\n{\n  var m, b; // Store data length in a local variable to reduce\n  // repeated object property lookups\n\n  var dataLength = data.length; //if there's only one point, arbitrarily choose a slope of 0\n  //and a y-intercept of whatever the y of the initial point is\n\n  if (dataLength === 1) {\n    m = 0;\n    b = data[0][1];\n  } else {\n    // Initialize our sums and scope the `m` and `b`\n    // variables that define the line.\n    var sumX = 0,\n        sumY = 0,\n        sumXX = 0,\n        sumXY = 0; // Use local variables to grab point values\n    // with minimal object property lookups\n\n    var point, x, y; // Gather the sum of all x values, the sum of all\n    // y values, and the sum of x^2 and (x*y) for each\n    // value.\n    //\n    // In math notation, these would be SS_x, SS_y, SS_xx, and SS_xy\n\n    for (var i = 0; i < dataLength; i++) {\n      point = data[i];\n      x = point[0];\n      y = point[1];\n      sumX += x;\n      sumY += y;\n      sumXX += x * x;\n      sumXY += x * y;\n    } // `m` is the slope of the regression line\n\n\n    m = (dataLength * sumXY - sumX * sumY) / (dataLength * sumXX - sumX * sumX); // `b` is the y-intercept of the line.\n\n    b = sumY / dataLength - m * sumX / dataLength;\n  } // Return both values as an object.\n\n\n  return {\n    m: m,\n    b: b\n  };\n}\n\nmodule.exports = linearRegression;","map":{"version":3,"sources":["/home/amax/Autoro/cabana/node_modules/simple-statistics/src/linear_regression.js"],"names":["linearRegression","data","m","b","dataLength","length","sumX","sumY","sumXX","sumXY","point","x","y","i","module","exports"],"mappings":"AAAA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,SAASA,gBAAT,CAA0BC;AAAI;AAA9B;AAA0D;AAAgC;AAEtF,MAAIC,CAAJ,EAAOC,CAAP,CAFsF,CAItF;AACA;;AACA,MAAIC,UAAU,GAAGH,IAAI,CAACI,MAAtB,CANsF,CAQtF;AACA;;AACA,MAAID,UAAU,KAAK,CAAnB,EAAsB;AAClBF,IAAAA,CAAC,GAAG,CAAJ;AACAC,IAAAA,CAAC,GAAGF,IAAI,CAAC,CAAD,CAAJ,CAAQ,CAAR,CAAJ;AACH,GAHD,MAGO;AACH;AACA;AACA,QAAIK,IAAI,GAAG,CAAX;AAAA,QAAcC,IAAI,GAAG,CAArB;AAAA,QACIC,KAAK,GAAG,CADZ;AAAA,QACeC,KAAK,GAAG,CADvB,CAHG,CAMH;AACA;;AACA,QAAIC,KAAJ,EAAWC,CAAX,EAAcC,CAAd,CARG,CAUH;AACA;AACA;AACA;AACA;;AACA,SAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGT,UAApB,EAAgCS,CAAC,EAAjC,EAAqC;AACjCH,MAAAA,KAAK,GAAGT,IAAI,CAACY,CAAD,CAAZ;AACAF,MAAAA,CAAC,GAAGD,KAAK,CAAC,CAAD,CAAT;AACAE,MAAAA,CAAC,GAAGF,KAAK,CAAC,CAAD,CAAT;AAEAJ,MAAAA,IAAI,IAAIK,CAAR;AACAJ,MAAAA,IAAI,IAAIK,CAAR;AAEAJ,MAAAA,KAAK,IAAIG,CAAC,GAAGA,CAAb;AACAF,MAAAA,KAAK,IAAIE,CAAC,GAAGC,CAAb;AACH,KAzBE,CA2BH;;;AACAV,IAAAA,CAAC,GAAG,CAAEE,UAAU,GAAGK,KAAd,GAAwBH,IAAI,GAAGC,IAAhC,KACEH,UAAU,GAAGI,KAAd,GAAwBF,IAAI,GAAGA,IADhC,CAAJ,CA5BG,CA+BH;;AACAH,IAAAA,CAAC,GAAII,IAAI,GAAGH,UAAR,GAAwBF,CAAC,GAAGI,IAAL,GAAaF,UAAxC;AACH,GA9CqF,CAgDtF;;;AACA,SAAO;AACHF,IAAAA,CAAC,EAAEA,CADA;AAEHC,IAAAA,CAAC,EAAEA;AAFA,GAAP;AAIH;;AAGDW,MAAM,CAACC,OAAP,GAAiBf,gBAAjB","sourcesContent":["'use strict';\n/* @flow */\n\n/**\n * [Simple linear regression](http://en.wikipedia.org/wiki/Simple_linear_regression)\n * is a simple way to find a fitted line\n * between a set of coordinates. This algorithm finds the slope and y-intercept of a regression line\n * using the least sum of squares.\n *\n * @param {Array<Array<number>>} data an array of two-element of arrays,\n * like `[[0, 1], [2, 3]]`\n * @returns {Object} object containing slope and intersect of regression line\n * @example\n * linearRegression([[0, 0], [1, 1]]); // => { m: 1, b: 0 }\n */\nfunction linearRegression(data/*: Array<Array<number>> */)/*: { m: number, b: number } */ {\n\n    var m, b;\n\n    // Store data length in a local variable to reduce\n    // repeated object property lookups\n    var dataLength = data.length;\n\n    //if there's only one point, arbitrarily choose a slope of 0\n    //and a y-intercept of whatever the y of the initial point is\n    if (dataLength === 1) {\n        m = 0;\n        b = data[0][1];\n    } else {\n        // Initialize our sums and scope the `m` and `b`\n        // variables that define the line.\n        var sumX = 0, sumY = 0,\n            sumXX = 0, sumXY = 0;\n\n        // Use local variables to grab point values\n        // with minimal object property lookups\n        var point, x, y;\n\n        // Gather the sum of all x values, the sum of all\n        // y values, and the sum of x^2 and (x*y) for each\n        // value.\n        //\n        // In math notation, these would be SS_x, SS_y, SS_xx, and SS_xy\n        for (var i = 0; i < dataLength; i++) {\n            point = data[i];\n            x = point[0];\n            y = point[1];\n\n            sumX += x;\n            sumY += y;\n\n            sumXX += x * x;\n            sumXY += x * y;\n        }\n\n        // `m` is the slope of the regression line\n        m = ((dataLength * sumXY) - (sumX * sumY)) /\n            ((dataLength * sumXX) - (sumX * sumX));\n\n        // `b` is the y-intercept of the line.\n        b = (sumY / dataLength) - ((m * sumX) / dataLength);\n    }\n\n    // Return both values as an object.\n    return {\n        m: m,\n        b: b\n    };\n}\n\n\nmodule.exports = linearRegression;\n"]},"metadata":{},"sourceType":"script"}